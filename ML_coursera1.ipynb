{
    "cells": [
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "In this notebook we try to practice all the classification algorithms that we learned in this course.\n\nWe load a dataset using Pandas library, and apply the following algorithms, and find the best one for this specific dataset by accuracy evaluation methods.\n\nLets first load required libraries:"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "import itertools\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import NullFormatter\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.ticker as ticker\nfrom sklearn import preprocessing\n%matplotlib inline",
            "execution_count": 10,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "# About dataset"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "This dataset is about past loans. The __Loan_train.csv__ data set includes details of 346 customers whose loan are already paid off or defaulted. It includes following fields:\n\n| Field          | Description                                                                           |\n|----------------|---------------------------------------------------------------------------------------|\n| Loan_status    | Whether a loan is paid off on in collection                                           |\n| Principal      | Basic principal loan amount at the                                                    |\n| Terms          | Origination terms which can be weekly (7 days), biweekly, and monthly payoff schedule |\n| Effective_date | When the loan got originated and took effects                                         |\n| Due_date       | Since it\u2019s one-time payoff schedule, each loan has one single due date                |\n| Age            | Age of applicant                                                                      |\n| Education      | Education of applicant                                                                |\n| Gender         | The gender of applicant                                                               |"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "!wget -O loan_train.csv https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0101ENv3/labs/loan_train.csv",
            "execution_count": 11,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "--2020-07-02 09:43:29--  https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0101ENv3/labs/loan_train.csv\nResolving s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)... 67.228.254.196\nConnecting to s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)|67.228.254.196|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 23101 (23K) [text/csv]\nSaving to: \u2018loan_train.csv\u2019\n\n100%[======================================>] 23,101      --.-K/s   in 0.002s  \n\n2020-07-02 09:43:29 (12.4 MB/s) - \u2018loan_train.csv\u2019 saved [23101/23101]\n\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### Load Data From CSV File  "
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df = pd.read_csv('loan_train.csv')\ndf.head()",
            "execution_count": 12,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 12,
                    "data": {
                        "text/plain": "   Unnamed: 0  Unnamed: 0.1 loan_status  Principal  terms effective_date  \\\n0           0             0     PAIDOFF       1000     30       9/8/2016   \n1           2             2     PAIDOFF       1000     30       9/8/2016   \n2           3             3     PAIDOFF       1000     15       9/8/2016   \n3           4             4     PAIDOFF       1000     30       9/9/2016   \n4           6             6     PAIDOFF       1000     30       9/9/2016   \n\n    due_date  age             education  Gender  \n0  10/7/2016   45  High School or Below    male  \n1  10/7/2016   33              Bechalor  female  \n2  9/22/2016   27               college    male  \n3  10/8/2016   28               college  female  \n4  10/8/2016   29               college    male  ",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Unnamed: 0.1</th>\n      <th>loan_status</th>\n      <th>Principal</th>\n      <th>terms</th>\n      <th>effective_date</th>\n      <th>due_date</th>\n      <th>age</th>\n      <th>education</th>\n      <th>Gender</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>PAIDOFF</td>\n      <td>1000</td>\n      <td>30</td>\n      <td>9/8/2016</td>\n      <td>10/7/2016</td>\n      <td>45</td>\n      <td>High School or Below</td>\n      <td>male</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>2</td>\n      <td>PAIDOFF</td>\n      <td>1000</td>\n      <td>30</td>\n      <td>9/8/2016</td>\n      <td>10/7/2016</td>\n      <td>33</td>\n      <td>Bechalor</td>\n      <td>female</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>3</td>\n      <td>PAIDOFF</td>\n      <td>1000</td>\n      <td>15</td>\n      <td>9/8/2016</td>\n      <td>9/22/2016</td>\n      <td>27</td>\n      <td>college</td>\n      <td>male</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>4</td>\n      <td>PAIDOFF</td>\n      <td>1000</td>\n      <td>30</td>\n      <td>9/9/2016</td>\n      <td>10/8/2016</td>\n      <td>28</td>\n      <td>college</td>\n      <td>female</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6</td>\n      <td>6</td>\n      <td>PAIDOFF</td>\n      <td>1000</td>\n      <td>30</td>\n      <td>9/9/2016</td>\n      <td>10/8/2016</td>\n      <td>29</td>\n      <td>college</td>\n      <td>male</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "# Data visualization and pre-processing\n"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "print(df['loan_status'].value_counts())\nprint(df['education'].value_counts())\nprint(df['Gender'].value_counts())",
            "execution_count": 13,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "PAIDOFF       260\nCOLLECTION     86\nName: loan_status, dtype: int64\nHigh School or Below    151\ncollege                 149\nBechalor                 44\nMaster or Above           2\nName: education, dtype: int64\nmale      294\nfemale     52\nName: Gender, dtype: int64\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "260 people have paid off the loan on time while 86 have gone into collection\nmale 294 and female 52 \namong them 151 are high school or below, 149 are college students and 2 ar master or above"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### Convert to date time object "
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df['due_date'] = pd.to_datetime(df['due_date'])\ndf['effective_date'] = pd.to_datetime(df['effective_date'])",
            "execution_count": 14,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "# Pre-processing:  Feature selection/extraction"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### Lets look at the day of the week people get the loan "
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df['dayofweek'] = df['effective_date'].dt.dayofweek\nbins = np.linspace(df.dayofweek.min(), df.dayofweek.max(), 10)\ng = sns.FacetGrid(df, col=\"Gender\", hue=\"loan_status\", palette=\"Set1\", col_wrap=2)\ng.map(plt.hist, 'dayofweek', bins=bins, ec=\"k\")\ng.axes[-1].legend()\nplt.show()",
            "execution_count": 15,
            "outputs": [
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": "<Figure size 432x216 with 2 Axes>",
                        "image/png": "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\n"
                    },
                    "metadata": {
                        "needs_background": "light"
                    }
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "We see that people who get the loan at the end of the week dont pay it off, so lets use Feature binarization to set a threshold values less then day 4 "
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df['weekend'] = df['dayofweek'].apply(lambda x: 1 if (x>3)  else 0)\ndf.head()",
            "execution_count": 16,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 16,
                    "data": {
                        "text/plain": "   Unnamed: 0  Unnamed: 0.1 loan_status  Principal  terms effective_date  \\\n0           0             0     PAIDOFF       1000     30     2016-09-08   \n1           2             2     PAIDOFF       1000     30     2016-09-08   \n2           3             3     PAIDOFF       1000     15     2016-09-08   \n3           4             4     PAIDOFF       1000     30     2016-09-09   \n4           6             6     PAIDOFF       1000     30     2016-09-09   \n\n    due_date  age             education  Gender  dayofweek  weekend  \n0 2016-10-07   45  High School or Below    male          3        0  \n1 2016-10-07   33              Bechalor  female          3        0  \n2 2016-09-22   27               college    male          3        0  \n3 2016-10-08   28               college  female          4        1  \n4 2016-10-08   29               college    male          4        1  ",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Unnamed: 0.1</th>\n      <th>loan_status</th>\n      <th>Principal</th>\n      <th>terms</th>\n      <th>effective_date</th>\n      <th>due_date</th>\n      <th>age</th>\n      <th>education</th>\n      <th>Gender</th>\n      <th>dayofweek</th>\n      <th>weekend</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>PAIDOFF</td>\n      <td>1000</td>\n      <td>30</td>\n      <td>2016-09-08</td>\n      <td>2016-10-07</td>\n      <td>45</td>\n      <td>High School or Below</td>\n      <td>male</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>2</td>\n      <td>PAIDOFF</td>\n      <td>1000</td>\n      <td>30</td>\n      <td>2016-09-08</td>\n      <td>2016-10-07</td>\n      <td>33</td>\n      <td>Bechalor</td>\n      <td>female</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>3</td>\n      <td>PAIDOFF</td>\n      <td>1000</td>\n      <td>15</td>\n      <td>2016-09-08</td>\n      <td>2016-09-22</td>\n      <td>27</td>\n      <td>college</td>\n      <td>male</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>4</td>\n      <td>PAIDOFF</td>\n      <td>1000</td>\n      <td>30</td>\n      <td>2016-09-09</td>\n      <td>2016-10-08</td>\n      <td>28</td>\n      <td>college</td>\n      <td>female</td>\n      <td>4</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6</td>\n      <td>6</td>\n      <td>PAIDOFF</td>\n      <td>1000</td>\n      <td>30</td>\n      <td>2016-09-09</td>\n      <td>2016-10-08</td>\n      <td>29</td>\n      <td>college</td>\n      <td>male</td>\n      <td>4</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## Convert Categorical features to numerical values"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df.groupby(['Gender'])['loan_status'].value_counts(normalize=True)",
            "execution_count": 17,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 17,
                    "data": {
                        "text/plain": "Gender  loan_status\nfemale  PAIDOFF        0.865385\n        COLLECTION     0.134615\nmale    PAIDOFF        0.731293\n        COLLECTION     0.268707\nName: loan_status, dtype: float64"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "86 % of female pay there loans while only 73 % of males pay there loan"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Lets convert male to 0 and female to 1:"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df['Gender'].replace(to_replace=['male','female'], value=[0,1],inplace=True)\ndf.head()\n",
            "execution_count": 18,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 18,
                    "data": {
                        "text/plain": "   Unnamed: 0  Unnamed: 0.1 loan_status  Principal  terms effective_date  \\\n0           0             0     PAIDOFF       1000     30     2016-09-08   \n1           2             2     PAIDOFF       1000     30     2016-09-08   \n2           3             3     PAIDOFF       1000     15     2016-09-08   \n3           4             4     PAIDOFF       1000     30     2016-09-09   \n4           6             6     PAIDOFF       1000     30     2016-09-09   \n\n    due_date  age             education  Gender  dayofweek  weekend  \n0 2016-10-07   45  High School or Below       0          3        0  \n1 2016-10-07   33              Bechalor       1          3        0  \n2 2016-09-22   27               college       0          3        0  \n3 2016-10-08   28               college       1          4        1  \n4 2016-10-08   29               college       0          4        1  ",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Unnamed: 0.1</th>\n      <th>loan_status</th>\n      <th>Principal</th>\n      <th>terms</th>\n      <th>effective_date</th>\n      <th>due_date</th>\n      <th>age</th>\n      <th>education</th>\n      <th>Gender</th>\n      <th>dayofweek</th>\n      <th>weekend</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>PAIDOFF</td>\n      <td>1000</td>\n      <td>30</td>\n      <td>2016-09-08</td>\n      <td>2016-10-07</td>\n      <td>45</td>\n      <td>High School or Below</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>2</td>\n      <td>PAIDOFF</td>\n      <td>1000</td>\n      <td>30</td>\n      <td>2016-09-08</td>\n      <td>2016-10-07</td>\n      <td>33</td>\n      <td>Bechalor</td>\n      <td>1</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>3</td>\n      <td>PAIDOFF</td>\n      <td>1000</td>\n      <td>15</td>\n      <td>2016-09-08</td>\n      <td>2016-09-22</td>\n      <td>27</td>\n      <td>college</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>4</td>\n      <td>PAIDOFF</td>\n      <td>1000</td>\n      <td>30</td>\n      <td>2016-09-09</td>\n      <td>2016-10-08</td>\n      <td>28</td>\n      <td>college</td>\n      <td>1</td>\n      <td>4</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6</td>\n      <td>6</td>\n      <td>PAIDOFF</td>\n      <td>1000</td>\n      <td>30</td>\n      <td>2016-09-09</td>\n      <td>2016-10-08</td>\n      <td>29</td>\n      <td>college</td>\n      <td>0</td>\n      <td>4</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## One Hot Encoding  \n#### How about education?"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df[['Principal','terms','age','Gender','education']].head()",
            "execution_count": 19,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 19,
                    "data": {
                        "text/plain": "   Principal  terms  age  Gender             education\n0       1000     30   45       0  High School or Below\n1       1000     30   33       1              Bechalor\n2       1000     15   27       0               college\n3       1000     30   28       1               college\n4       1000     30   29       0               college",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Principal</th>\n      <th>terms</th>\n      <th>age</th>\n      <th>Gender</th>\n      <th>education</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1000</td>\n      <td>30</td>\n      <td>45</td>\n      <td>0</td>\n      <td>High School or Below</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1000</td>\n      <td>30</td>\n      <td>33</td>\n      <td>1</td>\n      <td>Bechalor</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1000</td>\n      <td>15</td>\n      <td>27</td>\n      <td>0</td>\n      <td>college</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1000</td>\n      <td>30</td>\n      <td>28</td>\n      <td>1</td>\n      <td>college</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1000</td>\n      <td>30</td>\n      <td>29</td>\n      <td>0</td>\n      <td>college</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "Feature = df[['Principal','terms','age','Gender','weekend']]\nFeature = pd.concat([Feature,pd.get_dummies(df['education'])], axis=1)\nFeature.drop(['Master or Above'], axis = 1,inplace=True)\nFeature.head()",
            "execution_count": 20,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 20,
                    "data": {
                        "text/plain": "   Principal  terms  age  Gender  weekend  Bechalor  High School or Below  \\\n0       1000     30   45       0        0         0                     1   \n1       1000     30   33       1        0         1                     0   \n2       1000     15   27       0        0         0                     0   \n3       1000     30   28       1        1         0                     0   \n4       1000     30   29       0        1         0                     0   \n\n   college  \n0        0  \n1        0  \n2        1  \n3        1  \n4        1  ",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Principal</th>\n      <th>terms</th>\n      <th>age</th>\n      <th>Gender</th>\n      <th>weekend</th>\n      <th>Bechalor</th>\n      <th>High School or Below</th>\n      <th>college</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1000</td>\n      <td>30</td>\n      <td>45</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1000</td>\n      <td>30</td>\n      <td>33</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1000</td>\n      <td>15</td>\n      <td>27</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1000</td>\n      <td>30</td>\n      <td>28</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1000</td>\n      <td>30</td>\n      <td>29</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "#### Use one hot encoding technique to conver categorical varables to binary variables and append them to the feature Data Frame "
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### Feature selection"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "X = Feature\nX[0:5]",
            "execution_count": 21,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 21,
                    "data": {
                        "text/plain": "   Principal  terms  age  Gender  weekend  Bechalor  High School or Below  \\\n0       1000     30   45       0        0         0                     1   \n1       1000     30   33       1        0         1                     0   \n2       1000     15   27       0        0         0                     0   \n3       1000     30   28       1        1         0                     0   \n4       1000     30   29       0        1         0                     0   \n\n   college  \n0        0  \n1        0  \n2        1  \n3        1  \n4        1  ",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Principal</th>\n      <th>terms</th>\n      <th>age</th>\n      <th>Gender</th>\n      <th>weekend</th>\n      <th>Bechalor</th>\n      <th>High School or Below</th>\n      <th>college</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1000</td>\n      <td>30</td>\n      <td>45</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1000</td>\n      <td>30</td>\n      <td>33</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1000</td>\n      <td>15</td>\n      <td>27</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1000</td>\n      <td>30</td>\n      <td>28</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1000</td>\n      <td>30</td>\n      <td>29</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "y = df['loan_status'].values\ny[0:5]",
            "execution_count": 22,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 22,
                    "data": {
                        "text/plain": "array(['PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF'],\n      dtype=object)"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## Normalize Data "
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "X= preprocessing.StandardScaler().fit(X).transform(X)\nX[0:5]",
            "execution_count": 23,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype uint8, int64 were all converted to float64 by StandardScaler.\n  return self.partial_fit(X, y)\n/opt/conda/envs/Python36/lib/python3.6/site-packages/ipykernel/__main__.py:1: DataConversionWarning: Data with input dtype uint8, int64 were all converted to float64 by StandardScaler.\n  if __name__ == '__main__':\n",
                    "name": "stderr"
                },
                {
                    "output_type": "execute_result",
                    "execution_count": 23,
                    "data": {
                        "text/plain": "array([[ 0.51578458,  0.92071769,  2.33152555, -0.42056004, -1.20577805,\n        -0.38170062,  1.13639374, -0.86968108],\n       [ 0.51578458,  0.92071769,  0.34170148,  2.37778177, -1.20577805,\n         2.61985426, -0.87997669, -0.86968108],\n       [ 0.51578458, -0.95911111, -0.65321055, -0.42056004, -1.20577805,\n        -0.38170062, -0.87997669,  1.14984679],\n       [ 0.51578458,  0.92071769, -0.48739188,  2.37778177,  0.82934003,\n        -0.38170062, -0.87997669,  1.14984679],\n       [ 0.51578458,  0.92071769, -0.3215732 , -0.42056004,  0.82934003,\n        -0.38170062, -0.87997669,  1.14984679]])"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "# Classification "
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Now, it is your turn, use the training set to build an accurate model. Then use the test set to report the accuracy of the model\nYou should use the following algorithm:\n- K Nearest Neighbor(KNN)\n- Decision Tree\n- Support Vector Machine\n- Logistic Regression\n\n\n\n__ Notice:__ \n- You can go above and change the pre-processing, feature selection, feature-extraction, and so on, to make a better model.\n- You should use either scikit-learn, Scipy or Numpy libraries for developing the classification algorithms.\n- You should include the code of the algorithm in the following cells."
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## Question 1 Building model using KNN, finding the best k and accuracy evaluation (7 marks)\n\n- Anwers\n- part1\n - Below Code results perform the KNN using Sickit-learn.\n   - Train set Accuracy:  0.8115942028985508\n   - Test set Accuracy:  0.6857142857142857\n- part2\n  - Best K we can observe in the graph is 7, So best K = 7 \n- part3 \n  - The best accuracy was with 0.7857142857142857 with k= 7"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#KNN\n\nfrom sklearn.model_selection import train_test_split\nX_traink, X_testk, y_traink, y_testk = train_test_split( X, y, test_size=0.2, random_state=4)\nprint ('Train set:', X_traink.shape,  y_traink.shape)\nprint ('Test set:', X_testk.shape,  y_testk.shape)\n\nfrom sklearn.neighbors import KNeighborsClassifier\nk = 4\n#Train Model and Predict  \nneigh = KNeighborsClassifier(n_neighbors = k).fit(X_traink,y_traink)\nneigh\nyhatk = neigh.predict(X_testk)\n\nfrom sklearn import metrics\nprint(\"Train set Accuracy: \", metrics.accuracy_score(y_traink, neigh.predict(X_traink)))\nprint(\"Test set Accuracy: \", metrics.accuracy_score(y_testk, yhatk))\n",
            "execution_count": 27,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "Train set: (276, 8) (276,)\nTest set: (70, 8) (70,)\nTrain set Accuracy:  0.8152173913043478\nTest set Accuracy:  0.6857142857142857\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#Finding the best value of k\nKs = 15\nmean_acc = np.zeros((Ks-1))\nstd_acc = np.zeros((Ks-1))\nConfustionMx = [];\nfor n in range(1,Ks):\n    \n    #Train Model and Predict  \n    neigh = KNeighborsClassifier(n_neighbors = n).fit(X_traink,y_traink)\n    yhatk=neigh.predict(X_testk)\n    mean_acc[n-1] = metrics.accuracy_score(y_testk, yhatk)\n\n    \n    std_acc[n-1]=np.std(yhatk==y_testk)/np.sqrt(yhatk.shape[0])\n\nplt.plot(range(1,Ks),mean_acc,'g')\nplt.fill_between(range(1,Ks),mean_acc - 1 * std_acc,mean_acc + 1 * std_acc, alpha=0.10)\nplt.legend(('Accuracy ', '+/- 3xstd'))\nplt.ylabel('Accuracy ')\nplt.xlabel('Number of Nabors (K)')\nplt.tight_layout()\nplt.show()",
            "execution_count": 28,
            "outputs": [
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": "<Figure size 432x288 with 1 Axes>",
                        "image/png": "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\n"
                    },
                    "metadata": {
                        "needs_background": "light"
                    }
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "print( \"The best accuracy was with\", mean_acc.max(), \"with k=\", mean_acc.argmax()+1) ",
            "execution_count": 29,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "The best accuracy was with 0.7857142857142857 with k= 7\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "k = 13\n#Train Model and Predict  \nneighf = KNeighborsClassifier(n_neighbors = k).fit(X_traink,y_traink)\nneighf\nyhat2k = neighf.predict(X_testk)\nyhat2k\n\n",
            "execution_count": 31,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 31,
                    "data": {
                        "text/plain": "array(['PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF',\n       'COLLECTION', 'COLLECTION', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF',\n       'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF',\n       'COLLECTION', 'PAIDOFF', 'COLLECTION', 'PAIDOFF', 'PAIDOFF',\n       'PAIDOFF', 'COLLECTION', 'PAIDOFF', 'PAIDOFF', 'COLLECTION',\n       'COLLECTION', 'PAIDOFF', 'COLLECTION', 'PAIDOFF', 'PAIDOFF',\n       'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF',\n       'COLLECTION', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'COLLECTION',\n       'PAIDOFF', 'PAIDOFF', 'COLLECTION', 'PAIDOFF', 'PAIDOFF',\n       'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF',\n       'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF',\n       'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF',\n       'COLLECTION', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF',\n       'PAIDOFF', 'PAIDOFF'], dtype=object)"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Building the model again, using k=7\nfrom sklearn.neighbors import KNeighborsClassifier\nk = 7\n#Train Model and Predict  \nkNN_model = KNeighborsClassifier(n_neighbors=k).fit(X_traink,y_traink)\nkNN_model",
            "execution_count": 33,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 33,
                    "data": {
                        "text/plain": "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n           metric_params=None, n_jobs=None, n_neighbors=7, p=2,\n           weights='uniform')"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "# Decision Tree"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "# #Question 2: Building model using Decision Tree, finding the best k and accuracy evaluation (6 marks)\n\n\n\n- Anwers\n- part1\n - Below Code results perform the decision tree using Sickit-learn.\n   - DecisionTrees's Accuracy:  0.6634615384615384\n- part2\n  - Best K we can observe depth is 4, So best K = 4 \n- part3 \n  - The best accuracy DecisionTrees's Accuracy:  0.6826923076923077 and depth with k= 4"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#decession tree\nfrom sklearn.model_selection import train_test_split\nX_trainsetd, X_testsetd, y_trainsetd, y_testsetd = train_test_split(X, y, test_size=0.3, random_state=3)\nfrom sklearn.tree import DecisionTreeClassifier\ndecTree = DecisionTreeClassifier(criterion=\"entropy\",max_depth=10)\ndecTree.fit(X_trainsetd,y_trainsetd)\npredTree = decTree.predict(X_testsetd)\nfrom sklearn import metrics\nimport matplotlib.pyplot as plt\nprint(\"DecisionTrees's Accuracy: \", metrics.accuracy_score(y_testsetd, predTree))",
            "execution_count": 35,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "DecisionTrees's Accuracy:  0.6442307692307693\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from sklearn import decomposition, datasets\nfrom sklearn import tree\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import GridSearchCV\n# Create a pca object\npca = decomposition.PCA()\n\n# Create a logistic regression object with an L2 penalty\ndecisiontree = tree.DecisionTreeClassifier()\n\n#create a pipeline of three steps. First, standardize the data.\n# Second, tranform the data with PCA.\n# Third, train a Decision Tree Classifier on the data.\npipe = Pipeline(steps=[('pca', pca),('decisiontree', decisiontree)])\n\n# Create Parameter Space\n# Create a list of a sequence of integers from 1 to 30 (the number of features in X + 1)\nn_components = list(range(1,X.shape[1]+1,1))\n\n# Create lists of parameter for Decision Tree Classifier\ncriterion = ['gini', 'entropy']\nmax_depth = [4,6,8,12]\n\n# Create a dictionary of all the parameter options \n# Note has you can access the parameters of steps of a pipeline by using '__\u2019\nparameters = dict(pca__n_components=n_components,decisiontree__criterion=criterion,decisiontree__max_depth=max_depth)\n\n# Conduct Parameter Optmization With Pipeline\n# Create a grid search object\ndecTreef = GridSearchCV(pipe, parameters)\n\n# Fit the grid search\ndecTreef.fit(X_trainsetd,y_trainsetd)\n\n# View The Best Parameters\nprint('Best Criterion:', decTreef.best_estimator_.get_params()['decisiontree__criterion'])\nprint('Best max_depth:', decTreef.best_estimator_.get_params()['decisiontree__max_depth'])\nprint('Best Number Of Components:', decTreef.best_estimator_.get_params()['pca__n_components'])\nprint(); print(decTreef.best_estimator_.get_params()['decisiontree'])\n\ndecTreeff = DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,max_features=None, max_leaf_nodes=None,min_impurity_decrease=0.0, min_impurity_split=None,\n            min_samples_leaf=1, min_samples_split=2,\n            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n            splitter='best')\ndecTreeff.fit(X_trainsetd,y_trainsetd)\nprint(\"DecisionTrees's Accuracy: \", metrics.accuracy_score(y_testsetd, decTreeff.predict(X_testsetd)))",
            "execution_count": 36,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n  warnings.warn(CV_WARNING, FutureWarning)\n",
                    "name": "stderr"
                },
                {
                    "output_type": "stream",
                    "text": "Best Criterion: gini\nBest max_depth: 4\nBest Number Of Components: 1\n\nDecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n            max_features=None, max_leaf_nodes=None,\n            min_impurity_decrease=0.0, min_impurity_split=None,\n            min_samples_leaf=1, min_samples_split=2,\n            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n            splitter='best')\nDecisionTrees's Accuracy:  0.6826923076923077\n",
                    "name": "stdout"
                },
                {
                    "output_type": "stream",
                    "text": "/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n  DeprecationWarning)\n",
                    "name": "stderr"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "!conda install -c conda-forge pydotplus -y\n!conda install -c conda-forge python-graphviz -y",
            "execution_count": 38,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "Solving environment: done\n\n## Package Plan ##\n\n  environment location: /opt/conda/envs/Python36\n\n  added / updated specs: \n    - pydotplus\n\n\nThe following packages will be downloaded:\n\n    package                    |            build\n    ---------------------------|-----------------\n    certifi-2020.6.20          |   py36h9f0ad1d_0         151 KB  conda-forge\n    openssl-1.1.1g             |       h516909a_0         2.1 MB  conda-forge\n    python_abi-3.6             |          1_cp36m           4 KB  conda-forge\n    ca-certificates-2020.6.20  |       hecda079_0         145 KB  conda-forge\n    pydotplus-2.0.2            |     pyhd1c1de3_3          23 KB  conda-forge\n    ------------------------------------------------------------\n                                           Total:         2.4 MB\n\nThe following NEW packages will be INSTALLED:\n\n    pydotplus:       2.0.2-pyhd1c1de3_3 conda-forge\n    python_abi:      3.6-1_cp36m        conda-forge\n\nThe following packages will be UPDATED:\n\n    ca-certificates: 2020.1.1-0                     --> 2020.6.20-hecda079_0     conda-forge\n    certifi:         2020.6.20-py36_0               --> 2020.6.20-py36h9f0ad1d_0 conda-forge\n    openssl:         1.1.1g-h7b6447c_0              --> 1.1.1g-h516909a_0        conda-forge\n\n\nDownloading and Extracting Packages\ncertifi-2020.6.20    | 151 KB    | ##################################### | 100% \nopenssl-1.1.1g       | 2.1 MB    | ##################################### | 100% \npython_abi-3.6       | 4 KB      | ##################################### | 100% \nca-certificates-2020 | 145 KB    | ##################################### | 100% \npydotplus-2.0.2      | 23 KB     | ##################################### | 100% \nPreparing transaction: done\nVerifying transaction: done\nExecuting transaction: done\nSolving environment: \\ ^C\nfailed\n\nCondaError: KeyboardInterrupt\n\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from sklearn.externals.six import StringIO\nimport pydotplus\nimport matplotlib.image as mpimg\nfrom sklearn import tree\n%matplotlib inline \n\ndot_data = StringIO()\nfilename = \"Tree.png\"\nfeatureNames = my_data.columns[0:5]\ntargetNames = my_data[\"Loan\"].unique().tolist()\nout=tree.export_graphviz(drugTree,feature_names=featureNames, out_file=dot_data, class_names= np.unique(y_trainset), filled=True,  special_characters=True,rotate=False)  \ngraph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \ngraph.write_png(filename)\nimg = mpimg.imread(filename)\nplt.figure(figsize=(100, 200))\nplt.imshow(img,interpolation='nearest')",
            "execution_count": 37,
            "outputs": [
                {
                    "output_type": "error",
                    "ename": "ModuleNotFoundError",
                    "evalue": "No module named 'pydotplus'",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
                        "\u001b[0;32m<ipython-input-37-03aaf70e9136>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexternals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msix\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStringIO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpydotplus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmpimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pydotplus'"
                    ]
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "# Support Vector Machine\n"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## Question 3 : Building model using SVM, finding the best k and accuracy evaluation (6 marks)\n- Anwers\n- part1\n - Below Code results perform the SVM using Sickit-learn. Model Accurracy \n   - f1 score 0.7275882012724117\n   - jaccard score 0.7428571428571429\n"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#SVM\n\nX_trains, X_tests, y_trains, y_tests = train_test_split( X, y, test_size=0.2, random_state=4)\nprint ('Train set:', X_trains.shape,  y_trains.shape)\nprint ('Test set:', X_tests.shape,  y_tests.shape)\n\n\nfrom sklearn import svm\nfrom sklearn.svm import SVC\nclf = svm.SVC(kernel='rbf')\nclf.fit(X_trains, y_trains) \nyhats = clf.predict(X_tests)\nyhats",
            "execution_count": 47,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "Train set: (276, 8) (276,)\nTest set: (70, 8) (70,)\n",
                    "name": "stdout"
                },
                {
                    "output_type": "stream",
                    "text": "/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n  \"avoid this warning.\", FutureWarning)\n",
                    "name": "stderr"
                },
                {
                    "output_type": "execute_result",
                    "execution_count": 47,
                    "data": {
                        "text/plain": "array(['COLLECTION', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF',\n       'PAIDOFF', 'COLLECTION', 'COLLECTION', 'PAIDOFF', 'PAIDOFF',\n       'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF',\n       'COLLECTION', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF',\n       'PAIDOFF', 'COLLECTION', 'COLLECTION', 'PAIDOFF', 'COLLECTION',\n       'COLLECTION', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF',\n       'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF',\n       'PAIDOFF', 'COLLECTION', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF',\n       'PAIDOFF', 'COLLECTION', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF',\n       'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF',\n       'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF',\n       'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'COLLECTION',\n       'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF'],\n      dtype=object)"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "\n\nfrom sklearn.metrics import f1_score\nprint(\"f1 score\",f1_score(y_tests, yhats, average='weighted') )\n\nfrom sklearn.metrics import jaccard_similarity_score\nprint(\"jaccard score\",jaccard_similarity_score(y_tests, yhats))\n\nfrom sklearn.model_selection import GridSearchCV\nparam_grid = {'C': [0.01,0.1,1, 10, 100], 'gamma': [10,1,0.1,0.01],'kernel': ['rbf', 'linear', 'sigmoid']}\ngrid = GridSearchCV(SVC(),param_grid,refit=True,verbose=2)",
            "execution_count": 44,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "f1 score 0.7275882012724117\njaccard score 0.7428571428571429\n",
                    "name": "stdout"
                },
                {
                    "output_type": "stream",
                    "text": "/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n  \"avoid this warning.\", FutureWarning)\n",
                    "name": "stderr"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "grid.fit(X_trains,y_trains)\n",
            "execution_count": 31,
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n  warnings.warn(CV_WARNING, FutureWarning)\n[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Fitting 3 folds for each of 60 candidates, totalling 180 fits\n[CV] C=0.01, gamma=10, kernel=rbf ....................................\n[CV] ..................... C=0.01, gamma=10, kernel=rbf, total=   0.0s\n[CV] C=0.01, gamma=10, kernel=rbf ....................................\n[CV] ..................... C=0.01, gamma=10, kernel=rbf, total=   0.0s\n[CV] C=0.01, gamma=10, kernel=rbf ....................................\n[CV] ..................... C=0.01, gamma=10, kernel=rbf, total=   0.0s\n[CV] C=0.01, gamma=10, kernel=linear .................................\n[CV] .................. C=0.01, gamma=10, kernel=linear, total=   0.0s\n[CV] C=0.01, gamma=10, kernel=linear .................................\n[CV] .................. C=0.01, gamma=10, kernel=linear, total=   0.0s\n[CV] C=0.01, gamma=10, kernel=linear .................................\n[CV] .................. C=0.01, gamma=10, kernel=linear, total=   0.0s\n[CV] C=0.01, gamma=10, kernel=sigmoid ................................\n[CV] ................. C=0.01, gamma=10, kernel=sigmoid, total=   0.0s\n[CV] C=0.01, gamma=10, kernel=sigmoid ................................\n[CV] ................. C=0.01, gamma=10, kernel=sigmoid, total=   0.0s\n[CV] C=0.01, gamma=10, kernel=sigmoid ................................\n[CV] ................. C=0.01, gamma=10, kernel=sigmoid, total=   0.0s\n[CV] C=0.01, gamma=1, kernel=rbf .....................................\n[CV] ...................... C=0.01, gamma=1, kernel=rbf, total=   0.0s\n[CV] C=0.01, gamma=1, kernel=rbf .....................................\n[CV] ...................... C=0.01, gamma=1, kernel=rbf, total=   0.0s\n[CV] C=0.01, gamma=1, kernel=rbf .....................................\n[CV] ...................... C=0.01, gamma=1, kernel=rbf, total=   0.0s\n[CV] C=0.01, gamma=1, kernel=linear ..................................\n[CV] ................... C=0.01, gamma=1, kernel=linear, total=   0.0s\n[CV] C=0.01, gamma=1, kernel=linear ..................................\n[CV] ................... C=0.01, gamma=1, kernel=linear, total=   0.0s\n[CV] C=0.01, gamma=1, kernel=linear ..................................\n[CV] ................... C=0.01, gamma=1, kernel=linear, total=   0.0s\n[CV] C=0.01, gamma=1, kernel=sigmoid .................................\n[CV] .................. C=0.01, gamma=1, kernel=sigmoid, total=   0.0s\n[CV] C=0.01, gamma=1, kernel=sigmoid .................................\n[CV] .................. C=0.01, gamma=1, kernel=sigmoid, total=   0.0s\n[CV] C=0.01, gamma=1, kernel=sigmoid .................................\n[CV] .................. C=0.01, gamma=1, kernel=sigmoid, total=   0.0s\n[CV] C=0.01, gamma=0.1, kernel=rbf ...................................\n[CV] .................... C=0.01, gamma=0.1, kernel=rbf, total=   0.0s\n[CV] C=0.01, gamma=0.1, kernel=rbf ...................................\n[CV] .................... C=0.01, gamma=0.1, kernel=rbf, total=   0.0s\n[CV] C=0.01, gamma=0.1, kernel=rbf ...................................\n[CV] .................... C=0.01, gamma=0.1, kernel=rbf, total=   0.0s\n[CV] C=0.01, gamma=0.1, kernel=linear ................................\n[CV] ................. C=0.01, gamma=0.1, kernel=linear, total=   0.0s\n[CV] C=0.01, gamma=0.1, kernel=linear ................................\n[CV] ................. C=0.01, gamma=0.1, kernel=linear, total=   0.0s\n[CV] C=0.01, gamma=0.1, kernel=linear ................................\n[CV] ................. C=0.01, gamma=0.1, kernel=linear, total=   0.0s\n[CV] C=0.01, gamma=0.1, kernel=sigmoid ...............................\n[CV] ................ C=0.01, gamma=0.1, kernel=sigmoid, total=   0.0s\n[CV] C=0.01, gamma=0.1, kernel=sigmoid ...............................\n[CV] ................ C=0.01, gamma=0.1, kernel=sigmoid, total=   0.0s\n[CV] C=0.01, gamma=0.1, kernel=sigmoid ...............................\n[CV] ................ C=0.01, gamma=0.1, kernel=sigmoid, total=   0.0s\n[CV] C=0.01, gamma=0.01, kernel=rbf ..................................\n[CV] ................... C=0.01, gamma=0.01, kernel=rbf, total=   0.0s\n[CV] C=0.01, gamma=0.01, kernel=rbf ..................................\n[CV] ................... C=0.01, gamma=0.01, kernel=rbf, total=   0.0s\n[CV] C=0.01, gamma=0.01, kernel=rbf ..................................\n[CV] ................... C=0.01, gamma=0.01, kernel=rbf, total=   0.0s\n[CV] C=0.01, gamma=0.01, kernel=linear ...............................\n[CV] ................ C=0.01, gamma=0.01, kernel=linear, total=   0.0s\n[CV] C=0.01, gamma=0.01, kernel=linear ...............................\n[CV] ................ C=0.01, gamma=0.01, kernel=linear, total=   0.0s\n[CV] C=0.01, gamma=0.01, kernel=linear ...............................\n[CV] ................ C=0.01, gamma=0.01, kernel=linear, total=   0.0s\n[CV] C=0.01, gamma=0.01, kernel=sigmoid ..............................\n[CV] ............... C=0.01, gamma=0.01, kernel=sigmoid, total=   0.0s\n[CV] C=0.01, gamma=0.01, kernel=sigmoid ..............................\n[CV] ............... C=0.01, gamma=0.01, kernel=sigmoid, total=   0.0s\n[CV] C=0.01, gamma=0.01, kernel=sigmoid ..............................\n[CV] ............... C=0.01, gamma=0.01, kernel=sigmoid, total=   0.0s\n[CV] C=0.1, gamma=10, kernel=rbf .....................................\n[CV] ...................... C=0.1, gamma=10, kernel=rbf, total=   0.0s\n[CV] C=0.1, gamma=10, kernel=rbf .....................................\n[CV] ...................... C=0.1, gamma=10, kernel=rbf, total=   0.0s\n[CV] C=0.1, gamma=10, kernel=rbf .....................................\n[CV] ...................... C=0.1, gamma=10, kernel=rbf, total=   0.0s\n[CV] C=0.1, gamma=10, kernel=linear ..................................\n[CV] ................... C=0.1, gamma=10, kernel=linear, total=   0.0s\n[CV] C=0.1, gamma=10, kernel=linear ..................................\n[CV] ................... C=0.1, gamma=10, kernel=linear, total=   0.0s\n[CV] C=0.1, gamma=10, kernel=linear ..................................\n[CV] ................... C=0.1, gamma=10, kernel=linear, total=   0.0s\n[CV] C=0.1, gamma=10, kernel=sigmoid .................................\n[CV] .................. C=0.1, gamma=10, kernel=sigmoid, total=   0.0s\n[CV] C=0.1, gamma=10, kernel=sigmoid .................................\n[CV] .................. C=0.1, gamma=10, kernel=sigmoid, total=   0.0s\n[CV] C=0.1, gamma=10, kernel=sigmoid .................................\n[CV] .................. C=0.1, gamma=10, kernel=sigmoid, total=   0.0s\n[CV] C=0.1, gamma=1, kernel=rbf ......................................\n[CV] ....................... C=0.1, gamma=1, kernel=rbf, total=   0.0s\n[CV] C=0.1, gamma=1, kernel=rbf ......................................\n[CV] ....................... C=0.1, gamma=1, kernel=rbf, total=   0.0s\n[CV] C=0.1, gamma=1, kernel=rbf ......................................\n[CV] ....................... C=0.1, gamma=1, kernel=rbf, total=   0.0s\n[CV] C=0.1, gamma=1, kernel=linear ...................................\n[CV] .................... C=0.1, gamma=1, kernel=linear, total=   0.0s\n[CV] C=0.1, gamma=1, kernel=linear ...................................\n[CV] .................... C=0.1, gamma=1, kernel=linear, total=   0.0s\n[CV] C=0.1, gamma=1, kernel=linear ...................................\n[CV] .................... C=0.1, gamma=1, kernel=linear, total=   0.0s\n[CV] C=0.1, gamma=1, kernel=sigmoid ..................................\n[CV] ................... C=0.1, gamma=1, kernel=sigmoid, total=   0.0s\n[CV] C=0.1, gamma=1, kernel=sigmoid ..................................\n[CV] ................... C=0.1, gamma=1, kernel=sigmoid, total=   0.0s\n[CV] C=0.1, gamma=1, kernel=sigmoid ..................................\n[CV] ................... C=0.1, gamma=1, kernel=sigmoid, total=   0.0s\n[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n[CV] ..................... C=0.1, gamma=0.1, kernel=rbf, total=   0.0s\n[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n[CV] ..................... C=0.1, gamma=0.1, kernel=rbf, total=   0.0s\n[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n[CV] ..................... C=0.1, gamma=0.1, kernel=rbf, total=   0.0s\n[CV] C=0.1, gamma=0.1, kernel=linear .................................\n[CV] .................. C=0.1, gamma=0.1, kernel=linear, total=   0.0s\n[CV] C=0.1, gamma=0.1, kernel=linear .................................\n[CV] .................. C=0.1, gamma=0.1, kernel=linear, total=   0.0s\n[CV] C=0.1, gamma=0.1, kernel=linear .................................\n[CV] .................. C=0.1, gamma=0.1, kernel=linear, total=   0.0s\n[CV] C=0.1, gamma=0.1, kernel=sigmoid ................................\n[CV] ................. C=0.1, gamma=0.1, kernel=sigmoid, total=   0.0s\n[CV] C=0.1, gamma=0.1, kernel=sigmoid ................................\n[CV] ................. C=0.1, gamma=0.1, kernel=sigmoid, total=   0.0s\n[CV] C=0.1, gamma=0.1, kernel=sigmoid ................................\n[CV] ................. C=0.1, gamma=0.1, kernel=sigmoid, total=   0.0s\n[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n[CV] .................... C=0.1, gamma=0.01, kernel=rbf, total=   0.0s\n[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n[CV] .................... C=0.1, gamma=0.01, kernel=rbf, total=   0.0s\n[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n[CV] .................... C=0.1, gamma=0.01, kernel=rbf, total=   0.0s\n[CV] C=0.1, gamma=0.01, kernel=linear ................................\n[CV] ................. C=0.1, gamma=0.01, kernel=linear, total=   0.0s\n[CV] C=0.1, gamma=0.01, kernel=linear ................................\n[CV] ................. C=0.1, gamma=0.01, kernel=linear, total=   0.0s\n[CV] C=0.1, gamma=0.01, kernel=linear ................................\n[CV] ................. C=0.1, gamma=0.01, kernel=linear, total=   0.0s\n[CV] C=0.1, gamma=0.01, kernel=sigmoid ...............................\n[CV] ................ C=0.1, gamma=0.01, kernel=sigmoid, total=   0.0s\n[CV] C=0.1, gamma=0.01, kernel=sigmoid ...............................\n[CV] ................ C=0.1, gamma=0.01, kernel=sigmoid, total=   0.0s\n[CV] C=0.1, gamma=0.01, kernel=sigmoid ...............................\n[CV] ................ C=0.1, gamma=0.01, kernel=sigmoid, total=   0.0s\n[CV] C=1, gamma=10, kernel=rbf .......................................\n[CV] ........................ C=1, gamma=10, kernel=rbf, total=   0.0s\n[CV] C=1, gamma=10, kernel=rbf .......................................\n[CV] ........................ C=1, gamma=10, kernel=rbf, total=   0.0s\n[CV] C=1, gamma=10, kernel=rbf .......................................\n[CV] ........................ C=1, gamma=10, kernel=rbf, total=   0.0s\n[CV] C=1, gamma=10, kernel=linear ....................................\n[CV] ..................... C=1, gamma=10, kernel=linear, total=   0.0s\n[CV] C=1, gamma=10, kernel=linear ....................................\n[CV] ..................... C=1, gamma=10, kernel=linear, total=   0.0s\n[CV] C=1, gamma=10, kernel=linear ....................................\n[CV] ..................... C=1, gamma=10, kernel=linear, total=   0.0s\n[CV] C=1, gamma=10, kernel=sigmoid ...................................\n[CV] .................... C=1, gamma=10, kernel=sigmoid, total=   0.0s\n[CV] C=1, gamma=10, kernel=sigmoid ...................................\n[CV] .................... C=1, gamma=10, kernel=sigmoid, total=   0.0s\n[CV] C=1, gamma=10, kernel=sigmoid ...................................\n[CV] .................... C=1, gamma=10, kernel=sigmoid, total=   0.0s\n[CV] C=1, gamma=1, kernel=rbf ........................................\n[CV] ......................... C=1, gamma=1, kernel=rbf, total=   0.0s\n[CV] C=1, gamma=1, kernel=rbf ........................................\n[CV] ......................... C=1, gamma=1, kernel=rbf, total=   0.0s\n[CV] C=1, gamma=1, kernel=rbf ........................................\n[CV] ......................... C=1, gamma=1, kernel=rbf, total=   0.0s\n[CV] C=1, gamma=1, kernel=linear .....................................\n[CV] ...................... C=1, gamma=1, kernel=linear, total=   0.0s\n[CV] C=1, gamma=1, kernel=linear .....................................\n[CV] ...................... C=1, gamma=1, kernel=linear, total=   0.0s\n[CV] C=1, gamma=1, kernel=linear .....................................\n[CV] ...................... C=1, gamma=1, kernel=linear, total=   0.0s\n[CV] C=1, gamma=1, kernel=sigmoid ....................................\n[CV] ..................... C=1, gamma=1, kernel=sigmoid, total=   0.0s\n[CV] C=1, gamma=1, kernel=sigmoid ....................................\n[CV] ..................... C=1, gamma=1, kernel=sigmoid, total=   0.0s\n[CV] C=1, gamma=1, kernel=sigmoid ....................................\n[CV] ..................... C=1, gamma=1, kernel=sigmoid, total=   0.0s\n[CV] C=1, gamma=0.1, kernel=rbf ......................................\n[CV] ....................... C=1, gamma=0.1, kernel=rbf, total=   0.0s\n[CV] C=1, gamma=0.1, kernel=rbf ......................................\n[CV] ....................... C=1, gamma=0.1, kernel=rbf, total=   0.0s\n[CV] C=1, gamma=0.1, kernel=rbf ......................................\n[CV] ....................... C=1, gamma=0.1, kernel=rbf, total=   0.0s\n[CV] C=1, gamma=0.1, kernel=linear ...................................\n[CV] .................... C=1, gamma=0.1, kernel=linear, total=   0.0s\n[CV] C=1, gamma=0.1, kernel=linear ...................................\n[CV] .................... C=1, gamma=0.1, kernel=linear, total=   0.0s\n[CV] C=1, gamma=0.1, kernel=linear ...................................\n[CV] .................... C=1, gamma=0.1, kernel=linear, total=   0.0s\n[CV] C=1, gamma=0.1, kernel=sigmoid ..................................\n[CV] ................... C=1, gamma=0.1, kernel=sigmoid, total=   0.0s\n[CV] C=1, gamma=0.1, kernel=sigmoid ..................................\n[CV] ................... C=1, gamma=0.1, kernel=sigmoid, total=   0.0s\n[CV] C=1, gamma=0.1, kernel=sigmoid ..................................\n[CV] ................... C=1, gamma=0.1, kernel=sigmoid, total=   0.0s\n[CV] C=1, gamma=0.01, kernel=rbf .....................................\n[CV] ...................... C=1, gamma=0.01, kernel=rbf, total=   0.0s\n[CV] C=1, gamma=0.01, kernel=rbf .....................................\n[CV] ...................... C=1, gamma=0.01, kernel=rbf, total=   0.0s\n[CV] C=1, gamma=0.01, kernel=rbf .....................................\n[CV] ...................... C=1, gamma=0.01, kernel=rbf, total=   0.0s\n[CV] C=1, gamma=0.01, kernel=linear ..................................\n[CV] ................... C=1, gamma=0.01, kernel=linear, total=   0.0s\n[CV] C=1, gamma=0.01, kernel=linear ..................................\n[CV] ................... C=1, gamma=0.01, kernel=linear, total=   0.0s\n[CV] C=1, gamma=0.01, kernel=linear ..................................\n[CV] ................... C=1, gamma=0.01, kernel=linear, total=   0.0s\n[CV] C=1, gamma=0.01, kernel=sigmoid .................................\n[CV] .................. C=1, gamma=0.01, kernel=sigmoid, total=   0.0s\n[CV] C=1, gamma=0.01, kernel=sigmoid .................................\n[CV] .................. C=1, gamma=0.01, kernel=sigmoid, total=   0.0s\n[CV] C=1, gamma=0.01, kernel=sigmoid .................................\n[CV] .................. C=1, gamma=0.01, kernel=sigmoid, total=   0.0s\n[CV] C=10, gamma=10, kernel=rbf ......................................\n[CV] ....................... C=10, gamma=10, kernel=rbf, total=   0.0s\n[CV] C=10, gamma=10, kernel=rbf ......................................\n[CV] ....................... C=10, gamma=10, kernel=rbf, total=   0.0s\n[CV] C=10, gamma=10, kernel=rbf ......................................\n[CV] ....................... C=10, gamma=10, kernel=rbf, total=   0.0s\n[CV] C=10, gamma=10, kernel=linear ...................................\n[CV] .................... C=10, gamma=10, kernel=linear, total=   0.0s\n[CV] C=10, gamma=10, kernel=linear ...................................\n[CV] .................... C=10, gamma=10, kernel=linear, total=   0.0s\n[CV] C=10, gamma=10, kernel=linear ...................................\n[CV] .................... C=10, gamma=10, kernel=linear, total=   0.0s\n[CV] C=10, gamma=10, kernel=sigmoid ..................................\n[CV] ................... C=10, gamma=10, kernel=sigmoid, total=   0.0s\n[CV] C=10, gamma=10, kernel=sigmoid ..................................\n[CV] ................... C=10, gamma=10, kernel=sigmoid, total=   0.0s\n[CV] C=10, gamma=10, kernel=sigmoid ..................................\n[CV] ................... C=10, gamma=10, kernel=sigmoid, total=   0.0s\n[CV] C=10, gamma=1, kernel=rbf .......................................\n[CV] ........................ C=10, gamma=1, kernel=rbf, total=   0.0s\n[CV] C=10, gamma=1, kernel=rbf .......................................\n[CV] ........................ C=10, gamma=1, kernel=rbf, total=   0.0s\n[CV] C=10, gamma=1, kernel=rbf .......................................\n[CV] ........................ C=10, gamma=1, kernel=rbf, total=   0.0s\n[CV] C=10, gamma=1, kernel=linear ....................................\n[CV] ..................... C=10, gamma=1, kernel=linear, total=   0.0s\n[CV] C=10, gamma=1, kernel=linear ....................................\n[CV] ..................... C=10, gamma=1, kernel=linear, total=   0.0s\n[CV] C=10, gamma=1, kernel=linear ....................................\n[CV] ..................... C=10, gamma=1, kernel=linear, total=   0.0s\n[CV] C=10, gamma=1, kernel=sigmoid ...................................\n[CV] .................... C=10, gamma=1, kernel=sigmoid, total=   0.0s\n[CV] C=10, gamma=1, kernel=sigmoid ...................................\n[CV] .................... C=10, gamma=1, kernel=sigmoid, total=   0.0s\n[CV] C=10, gamma=1, kernel=sigmoid ...................................\n[CV] .................... C=10, gamma=1, kernel=sigmoid, total=   0.0s\n[CV] C=10, gamma=0.1, kernel=rbf .....................................\n[CV] ...................... C=10, gamma=0.1, kernel=rbf, total=   0.0s\n[CV] C=10, gamma=0.1, kernel=rbf .....................................\n[CV] ...................... C=10, gamma=0.1, kernel=rbf, total=   0.0s\n[CV] C=10, gamma=0.1, kernel=rbf .....................................\n[CV] ...................... C=10, gamma=0.1, kernel=rbf, total=   0.0s\n[CV] C=10, gamma=0.1, kernel=linear ..................................\n[CV] ................... C=10, gamma=0.1, kernel=linear, total=   0.0s\n[CV] C=10, gamma=0.1, kernel=linear ..................................\n[CV] ................... C=10, gamma=0.1, kernel=linear, total=   0.0s\n[CV] C=10, gamma=0.1, kernel=linear ..................................\n[CV] ................... C=10, gamma=0.1, kernel=linear, total=   0.0s\n[CV] C=10, gamma=0.1, kernel=sigmoid .................................\n[CV] .................. C=10, gamma=0.1, kernel=sigmoid, total=   0.0s\n[CV] C=10, gamma=0.1, kernel=sigmoid .................................\n[CV] .................. C=10, gamma=0.1, kernel=sigmoid, total=   0.0s\n[CV] C=10, gamma=0.1, kernel=sigmoid .................................\n[CV] .................. C=10, gamma=0.1, kernel=sigmoid, total=   0.0s\n[CV] C=10, gamma=0.01, kernel=rbf ....................................\n[CV] ..................... C=10, gamma=0.01, kernel=rbf, total=   0.0s\n[CV] C=10, gamma=0.01, kernel=rbf ....................................\n[CV] ..................... C=10, gamma=0.01, kernel=rbf, total=   0.0s\n[CV] C=10, gamma=0.01, kernel=rbf ....................................\n[CV] ..................... C=10, gamma=0.01, kernel=rbf, total=   0.0s\n[CV] C=10, gamma=0.01, kernel=linear .................................\n[CV] .................. C=10, gamma=0.01, kernel=linear, total=   0.0s\n[CV] C=10, gamma=0.01, kernel=linear .................................\n[CV] .................. C=10, gamma=0.01, kernel=linear, total=   0.0s\n[CV] C=10, gamma=0.01, kernel=linear .................................\n[CV] .................. C=10, gamma=0.01, kernel=linear, total=   0.0s\n[CV] C=10, gamma=0.01, kernel=sigmoid ................................\n[CV] ................. C=10, gamma=0.01, kernel=sigmoid, total=   0.0s\n[CV] C=10, gamma=0.01, kernel=sigmoid ................................\n[CV] ................. C=10, gamma=0.01, kernel=sigmoid, total=   0.0s\n[CV] C=10, gamma=0.01, kernel=sigmoid ................................\n[CV] ................. C=10, gamma=0.01, kernel=sigmoid, total=   0.0s\n[CV] C=100, gamma=10, kernel=rbf .....................................\n[CV] ...................... C=100, gamma=10, kernel=rbf, total=   0.0s\n[CV] C=100, gamma=10, kernel=rbf .....................................\n[CV] ...................... C=100, gamma=10, kernel=rbf, total=   0.0s\n[CV] C=100, gamma=10, kernel=rbf .....................................\n[CV] ...................... C=100, gamma=10, kernel=rbf, total=   0.0s\n[CV] C=100, gamma=10, kernel=linear ..................................\n[CV] ................... C=100, gamma=10, kernel=linear, total=   0.0s\n[CV] C=100, gamma=10, kernel=linear ..................................\n[CV] ................... C=100, gamma=10, kernel=linear, total=   0.0s\n[CV] C=100, gamma=10, kernel=linear ..................................\n[CV] ................... C=100, gamma=10, kernel=linear, total=   0.0s\n[CV] C=100, gamma=10, kernel=sigmoid .................................\n[CV] .................. C=100, gamma=10, kernel=sigmoid, total=   0.0s\n[CV] C=100, gamma=10, kernel=sigmoid .................................\n[CV] .................. C=100, gamma=10, kernel=sigmoid, total=   0.0s\n[CV] C=100, gamma=10, kernel=sigmoid .................................\n[CV] .................. C=100, gamma=10, kernel=sigmoid, total=   0.0s\n[CV] C=100, gamma=1, kernel=rbf ......................................\n[CV] ....................... C=100, gamma=1, kernel=rbf, total=   0.0s\n[CV] C=100, gamma=1, kernel=rbf ......................................\n[CV] ....................... C=100, gamma=1, kernel=rbf, total=   0.0s\n[CV] C=100, gamma=1, kernel=rbf ......................................\n[CV] ....................... C=100, gamma=1, kernel=rbf, total=   0.0s\n[CV] C=100, gamma=1, kernel=linear ...................................\n[CV] .................... C=100, gamma=1, kernel=linear, total=   0.0s\n[CV] C=100, gamma=1, kernel=linear ...................................\n[CV] .................... C=100, gamma=1, kernel=linear, total=   0.0s\n[CV] C=100, gamma=1, kernel=linear ...................................\n[CV] .................... C=100, gamma=1, kernel=linear, total=   0.0s\n[CV] C=100, gamma=1, kernel=sigmoid ..................................\n[CV] ................... C=100, gamma=1, kernel=sigmoid, total=   0.0s\n[CV] C=100, gamma=1, kernel=sigmoid ..................................\n[CV] ................... C=100, gamma=1, kernel=sigmoid, total=   0.0s\n[CV] C=100, gamma=1, kernel=sigmoid ..................................\n[CV] ................... C=100, gamma=1, kernel=sigmoid, total=   0.0s\n[CV] C=100, gamma=0.1, kernel=rbf ....................................\n[CV] ..................... C=100, gamma=0.1, kernel=rbf, total=   0.0s\n[CV] C=100, gamma=0.1, kernel=rbf ....................................\n[CV] ..................... C=100, gamma=0.1, kernel=rbf, total=   0.0s\n[CV] C=100, gamma=0.1, kernel=rbf ....................................\n[CV] ..................... C=100, gamma=0.1, kernel=rbf, total=   0.0s\n[CV] C=100, gamma=0.1, kernel=linear .................................\n[CV] .................. C=100, gamma=0.1, kernel=linear, total=   0.0s\n[CV] C=100, gamma=0.1, kernel=linear .................................\n[CV] .................. C=100, gamma=0.1, kernel=linear, total=   0.0s\n[CV] C=100, gamma=0.1, kernel=linear .................................\n[CV] .................. C=100, gamma=0.1, kernel=linear, total=   0.0s\n[CV] C=100, gamma=0.1, kernel=sigmoid ................................\n[CV] ................. C=100, gamma=0.1, kernel=sigmoid, total=   0.0s\n[CV] C=100, gamma=0.1, kernel=sigmoid ................................\n[CV] ................. C=100, gamma=0.1, kernel=sigmoid, total=   0.0s\n[CV] C=100, gamma=0.1, kernel=sigmoid ................................\n[CV] ................. C=100, gamma=0.1, kernel=sigmoid, total=   0.0s\n[CV] C=100, gamma=0.01, kernel=rbf ...................................\n[CV] .................... C=100, gamma=0.01, kernel=rbf, total=   0.0s\n[CV] C=100, gamma=0.01, kernel=rbf ...................................\n[CV] .................... C=100, gamma=0.01, kernel=rbf, total=   0.0s\n[CV] C=100, gamma=0.01, kernel=rbf ...................................\n[CV] .................... C=100, gamma=0.01, kernel=rbf, total=   0.0s\n[CV] C=100, gamma=0.01, kernel=linear ................................\n[CV] ................. C=100, gamma=0.01, kernel=linear, total=   0.0s\n[CV] C=100, gamma=0.01, kernel=linear ................................\n[CV] ................. C=100, gamma=0.01, kernel=linear, total=   0.0s\n[CV] C=100, gamma=0.01, kernel=linear ................................\n[CV] ................. C=100, gamma=0.01, kernel=linear, total=   0.0s\n[CV] C=100, gamma=0.01, kernel=sigmoid ...............................\n[CV] ................ C=100, gamma=0.01, kernel=sigmoid, total=   0.0s\n[CV] C=100, gamma=0.01, kernel=sigmoid ...............................\n[CV] ................ C=100, gamma=0.01, kernel=sigmoid, total=   0.0s\n[CV] C=100, gamma=0.01, kernel=sigmoid ...............................\n[CV] ................ C=100, gamma=0.01, kernel=sigmoid, total=   0.0s\nAvg F1-score: 0.6973\nJaccard score: 0.7143\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "[Parallel(n_jobs=1)]: Done 180 out of 180 | elapsed:    1.0s finished\n/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n  DeprecationWarning)\n"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "print(\"Avg F1-score: %.4f\" % f1_score(y_tests,grid.predict(X_tests), average='weighted'))\nprint(\"Jaccard score: %.4f\" % jaccard_similarity_score(y_tests,grid.predict(X_tests)))",
            "execution_count": 32,
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Avg F1-score: 0.6973\nJaccard score: 0.7143\n"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "clf2 = svm.SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0,\n  decision_function_shape='ovr', degree=3, gamma=1, kernel='sigmoid',\n  max_iter=-1, probability=False, random_state=None, shrinking=True,\n  tol=0.001, verbose=False)\nclf2.fit(X_trains, y_trains) \nyhat2s = clf2.predict(X_tests)\nprint(\"Avg F1-score: %.4f\" % f1_score(y_tests, yhat2s, average='weighted'))\nprint(\"Jaccard score: %.4f\" % jaccard_similarity_score(y_tests, yhat2s))",
            "execution_count": 33,
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Avg F1-score: 0.6973\nJaccard score: 0.7143\n"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "# Logistic Regression\n"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## Building model using Logistic Regression, finding the best k and accuracy evaluation (6 marks)\n  - LogLoss: : 0.49\n  - k = 0.1\n  - best k = 0.1 leads to 0.49 loss \n"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "## logistic regression\n\nX_trainl, X_testl, y_trainl, y_testl = train_test_split( X, y, test_size=0.2, random_state=4)\nprint ('Train set:', X_trainl.shape,  y_trainl.shape)\nprint ('Test set:', X_testl.shape,  y_testl.shape)\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import confusion_matrix\nLR = LogisticRegression(C=0.1, solver='liblinear').fit(X_trainl,y_trainl)\nyhatl = LR.predict(X_testl)\n\nyhat_prob = LR.predict_proba(X_testl)\n#yhat_prob",
            "execution_count": 52,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "Train set: (276, 8) (276,)\nTest set: (70, 8) (70,)\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from sklearn.metrics import log_loss\nprint(\"Avg F1-score: %.4f\" % f1_score(y_testl, yhatl, average='weighted'))\nprint(\"Jaccard score: %.4f\" % jaccard_similarity_score(y_testl, yhatl))\nprint (\"LogLoss: : %.2f\" % log_loss(y_testl, yhat_prob))",
            "execution_count": 35,
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Avg F1-score: 0.7048\nJaccard score: 0.7429\nLogLoss: : 0.50\n"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "grid={\"C\":np.logspace(-3,3,7), \"solver\":[\"liblinear\",\"sag\",\"newton-cg\",\"lbfgs\"]}\nLRf=GridSearchCV(LogisticRegression(),grid,cv=10)\n",
            "execution_count": 37,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "f=GridSearchCV(LogisticRegression(),grid,cv=10)\nLRf.fit(X_trainl,y_trainl)\nprint(\"tuned hpyerparameters :(best parameters) \",LRf.best_params_)\nprint(\"Avg F1-score: %.4f\" % f1_score(y_testl, LRf.predict(X_testl), average='weighted'))\nprint(\"Jaccard score: %.4f\" % jaccard_similarity_score(y_testl, LRf.predict(X_testl)))\nprint (\"LogLoss: : %.2f\" % log_loss(y_testl, LRf.predict_proba(X_testl)))",
            "execution_count": 38,
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "tuned hpyerparameters :(best parameters)  {'C': 0.1, 'solver': 'liblinear'}\nAvg F1-score: 0.7048\nJaccard score: 0.7429\nLogLoss: : 0.50\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n  DeprecationWarning)\n"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "LR2 = LogisticRegression(C=0.01, solver='sag').fit(X_trainl,y_trainl)\nyhat_prob2 = LR2.predict_proba(X_testl)\nprint (\"LogLoss: : %.2f\" % log_loss(y_testl, yhat_prob2))",
            "execution_count": 63,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "LogLoss: : 0.49\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "LR2 = LogisticRegression(C=0.01, solver='sag').fit(X_trainl,y_trainl)\nyhat_prob3 = LR2.predict_proba(X_testl)\nprint (\"LogLoss: : %.2f\" % log_loss(y_testl, yhat_prob3))",
            "execution_count": 64,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "LogLoss: : 0.49\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "LR2 = LogisticRegression(C=0.01, solver='sag').fit(X_trainl,y_trainl)\nyhat_prob4 = LR2.predict_proba(X_testl)\nprint (\"LogLoss: : %.2f\" % log_loss(y_testl, yhat_prob4))",
            "execution_count": 65,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "LogLoss: : 0.49\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "# Model Evaluation using Test set"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "### MODEL EVAL\n\nfrom sklearn.metrics import jaccard_similarity_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import log_loss",
            "execution_count": 54,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "First, download and load the test set:"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "!wget -O loan_test.csv https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0101ENv3/labs/loan_test.csv",
            "execution_count": 53,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "--2020-07-02 10:39:31--  https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0101ENv3/labs/loan_test.csv\nResolving s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)... 67.228.254.196\nConnecting to s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)|67.228.254.196|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 3642 (3.6K) [text/csv]\nSaving to: \u2018loan_test.csv\u2019\n\n100%[======================================>] 3,642       --.-K/s   in 0s      \n\n2020-07-02 10:39:31 (390 MB/s) - \u2018loan_test.csv\u2019 saved [3642/3642]\n\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "test_df = pd.read_csv('loan_test.csv')",
            "execution_count": 55,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "test_df['due_date'] = pd.to_datetime(test_df['due_date'])\ntest_df['effective_date'] = pd.to_datetime(test_df['effective_date'])\n\ntest_df['dayofweek'] = test_df['effective_date'].dt.dayofweek\ntest_df['weekend'] = test_df['dayofweek'].apply(lambda x: 1 if (x>4)  else 0)\ntest_df['Gender'].replace(to_replace=['male','female'], value=[0,1],inplace=True)",
            "execution_count": 56,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "Feature = test_df[['Principal','age','Gender','terms','weekend']]\nFeature = pd.concat([Feature,pd.get_dummies(test_df['education'])], axis=1)\nFeature.drop(['Master or Above'], axis = 1,inplace=True)",
            "execution_count": 57,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "X_t = Feature\ny_t = test_df['loan_status'].values\nX_t= preprocessing.StandardScaler().fit(X_t).transform(X_t)",
            "execution_count": 58,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype uint8, int64 were all converted to float64 by StandardScaler.\n  return self.partial_fit(X, y)\n/opt/conda/envs/Python36/lib/python3.6/site-packages/ipykernel/__main__.py:3: DataConversionWarning: Data with input dtype uint8, int64 were all converted to float64 by StandardScaler.\n  app.launch_new_instance()\n",
                    "name": "stderr"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "test_y = test_df['loan_status'].values\ntest_y[0:5]",
            "execution_count": 70,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 70,
                    "data": {
                        "text/plain": "array(['PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF'],\n      dtype=object)"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "knnf=f1_score(y_t,neighf.predict(X_t), average='weighted')\nknnj=jaccard_similarity_score(y_t,neighf.predict(X_t))",
            "execution_count": 72,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "dtf=f1_score(y_t, decTreeff.predict(X_t), average='weighted')\ndtj=jaccard_similarity_score(y_t, decTreeff.predict(X_t))",
            "execution_count": 73,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "svmf=f1_score(y_t, clf.predict(X_t), average='weighted')\nsvmj=jaccard_similarity_score(y_t, clf.predict(X_t))",
            "execution_count": 74,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "lrf=f1_score(y_t, LR2.predict(X_t), average='weighted',labels=np.unique(LR2.predict(X_t)))\nlrj=jaccard_similarity_score(y_t, LR2.predict(X_t))",
            "execution_count": 75,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "lrll=log_loss(y_t, LR2.predict_proba(X_t))",
            "execution_count": 76,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "LR_yhat = LR2.predict(X_t)\nLR_yhat_prob = LR2.predict_proba(X_t)\nprint(\"LR Jaccard index: %.2f\" % jaccard_similarity_score(test_y, LR_yhat))\nprint(\"LR F1-score: %.2f\" % f1_score(test_y, LR_yhat, average='weighted') )\nprint(\"LR LogLoss: %.2f\" % log_loss(test_y, LR_yhat_prob))",
            "execution_count": 77,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "LR Jaccard index: 0.74\nLR F1-score: 0.63\nLR LogLoss: 0.54\n",
                    "name": "stdout"
                },
                {
                    "output_type": "stream",
                    "text": "/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n  'precision', 'predicted', average, warn_for)\n",
                    "name": "stderr"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "| Algorithm          | Jaccard | F1-score | LogLoss |\n|--------------------|---------|----------|---------|\n| KNN                | 0.67    | 0.63     | NA      |\n| Decision Tree      | 0.72    | 0.74     | NA      |\n| SVM                | 0.80    | 0.76     | NA      |\n| LogisticRegression | 0.74    | 0.63     | 0.54  |"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.6",
            "language": "python"
        },
        "language_info": {
            "name": "python",
            "version": "3.6.9",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}